\section{Introduction}\label{sec:introduction}

Programming of industrial robots for assembly operations is a meticulous and arduous task that requires a significant engineering effort and long testing and deployment phases. For high volume manufacturing this cost is acceptable, but it is too expensive to repurpose robots for small volume production using traditional programming approaches. These issues can be overcome with robots that can learn new assembly skills by observing experienced operators and interacting with them through natural language. To achieve these goals, the robot needs to successfully recognize the objects within its workspace and semantically track their pose with high precision while the operator demonstrates how to perform the assembly operations. Moreover, it must be able to understand any instructions that the operator might give and also have the ability to recall them if asked later on. This type of teaching allows rapid reprogramming of flexible robotic assembly cells for new tasks. This process can be speed up further if there are assembly manuals available, which allows the robotic system to extract the objects and their assembly spacial disposition from the textual and visual representations. By knowing which objects to expect for a given teaching session, the object recognition efficiency can be significantly increased (by limiting the object search database). Moreover, this preliminary information extraction phase reduces the human teaching phase to only the operations that lack detailed information.

This paper presents a dataset for evaluating \gls{ner} systems using assembly instructions of alternators, gearboxes and engines in several writing styles, from highly professional and structured text to colloquial and informal language. These assembly operations were extracted from \gls{pdf} files that besides textual descriptions also had assembly pictures and diagrams. As such, this dataset can be used for evaluating systems that combine both natural language processing algorithms and also computer vision and information extraction systems. For evaluating these \gls{nlp} systems using this dataset, each assembly operation has a list with the main assembly objects and their required quantity for successfully performing the product assembly. For speeding up testing, it is provided two versions of the dataset, one with already tokenized text and another with the original text. Moreover, the dataset is already split into 75\% of training text and 25\% of testing text.

In the following section it will be given a brief overview of applications of \gls{nlp} in robotics and also the main related work on extraction of assembly information from textual representations. \Cref{sec:dataset-sources} describes the main dataset sources for the 3 product types with assembly operations. \Cref{sec:dataset-preparation} presents the main steps that were performed to extract and clean the text from the \glspl{pdf}. In \cref{sec:n-grams} it is presented rank-frequency graphs for the tokenized dataset n-grams. Later on, it is shown the evaluation of the n-gram language models (from unigrams to pentagrams) and is also listed some sentences generated using these models. Finally, \cref{sec:conclusions} presents the conclusions and \cref{sec:future-work} gives an overview of future work that can be done to extract assembly information from this dataset.
