\section{Future work}\label{sec:future-work}

Future work for this dataset would include the tagging of all named entities in each assembly operation (instead of having a list for the entire procedure). Moreover, the assembly graph containing both the assembly order and the spatial disposition of the product components would be useful for validating more complex information extraction systems which intend to recover the full assembly knowledge from the text and image representation alone (without operator assistance).

For a system which aims to extract only the named entities in the assembly operations for speeding up object recognition (by restricting the database of object models to search for and recognize), it would be useful to start with the raw text from the \glspl{pdf} and perform an initial text preprocessing. This stage could include word tokenization, sentence splitting, \gls{pos} tagging and morphological analysis. Latter on, it could be used a gazetter in conjunction with machine learning algorithms (such as \glspl{hmm} or \glspl{crf}) to detect the named entities in the textual assembly operations. After having the named entities, it could be used an orthographic matcher to perform named entity coreference to find different mentions of the same entity and also type disambiguation in order to use word context to make sure that the semantic analysis was correct. The evaluation of a system with these goals can be done by comparing the list of named entities identified as assembly objects with the dataset validation list of product object components. Moreover, if the dataset has named entities tags for each word in the testing dataset, then a more complete evaluation can be done, allowing to assess the reliability of the entity disambiguation and coreference algorithms. Either way, this evaluation would result in the computation of the precision, recall, accuracy and F1 scores for the recognized entities given the list of entities that the \gls{ner} system was supposed to detect using a k-fold cross validation approach to split the dataset into training and test text.
