\begin{abstract}

Teaching industrial robots by demonstration can significantly decrease the re-purposing costs of assembly lines worldwide. To achieve this goal, the robot needs to semantically detect and track each object component with high accuracy. To speedup the object recognition phase, the learning system could gather information from assembly manuals in order to identify which objects are required for assembling the new product and if possible also extract the assembly order and spatial relation between them. This paper presents a dataset to test a \gls{ner} system with these goals. The dataset contains assembly operations for alternators, gearboxes and engines, which were written in a language discourse that ranges from professional to informal. For validating a given \gls{ner} system with this dataset, each assembly operation has a list of the named entities and the required quantities for performing the product assembly. This allows to evaluate \gls{ner} systems using precision, recall, accuracy and F1 scores. The dataset can also be used to evaluate information extraction and computer vision systems, since most assembly operations have pictures of the objects to assemble and also diagrams showing the necessary product parts, their assembly order and spacial disposition.

\end{abstract}
